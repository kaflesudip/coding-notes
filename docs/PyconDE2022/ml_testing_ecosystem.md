# Machine Learning Testing Ecosystem of Python

- Yunus Emrah Bulut
- https://2022.pycon.de/program/9UB3Z3/

- How to audit ML models?
  - Researchers have identified vulnerabilites in ML model.



## Vulnerabilites of ML

1. adversial attack
2. Leaking private info
3. Results are unexplainable
4. Can be unfair in decision making



## 1. Evasion attack.

- E.g. Tesla autopilot was fooled driving from 35kmph to 85 kmph
  - https://electrek.co/2020/02/19/tesla-autopilot-tricked-accelerate-speed-limit-sign/
- A tape was used in Speed sign.



## 2. membership inference attack

## 3. Physical attack

## 4. Biased decision

- Make biased decision from data they are trained from

## 5. Change in Data distribtuion

- Relation between features and target changes
- e.g. COVID period



## Regulators

- EU regulations has mandatory 
  - validation for High Risk AI system (HRAI)

## Tools:

1. ART - adversirial robustness tool
2. cleverbans
3. Fairlearn: Python package



## Validiator

- New tool developed by the author and university